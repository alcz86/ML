{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deadpool NLP analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "grSY3Bq0LP57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Deadpool movie NLP analysis**"
      ]
    },
    {
      "metadata": {
        "id": "vH7jIXENL3jP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "from nltk import word_tokenize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQ60y7VZK8kl",
        "colab_type": "code",
        "outputId": "44f4f7a8-3d37-4ecb-9673-306d966976d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHz9jcdyLfLN",
        "colab_type": "code",
        "outputId": "0197330c-5ead-4867-944a-3c8f4b0f2add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Get path with dialogues\n",
        "path  = '/content/gdrive/\"My Drive\"/data/deadpool/'\n",
        "!ls {path}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deadpool_new.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WiDt-us-L32x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/data/deadpool/deadpool_new.csv\", sep=';')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EOV8smvZR80N",
        "colab_type": "code",
        "outputId": "94223048-38f3-4a8c-e78a-599c9bead051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Kinda lonesome back here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Little help?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Sir, I have to keep my hands on the wheel.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Excuse me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Dopinder.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                                         TEXT\n",
              "0  DEADPOOL                    Kinda lonesome back here.\n",
              "1  DEADPOOL                                 Little help?\n",
              "2  DOPINDER   Sir, I have to keep my hands on the wheel.\n",
              "3  DEADPOOL                                   Excuse me.\n",
              "4  DOPINDER                                    Dopinder."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "HDFSIqEnSOTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How much sentences people said?\n"
      ]
    },
    {
      "metadata": {
        "id": "WtD8ybbGSVlO",
        "colab_type": "code",
        "outputId": "50b69475-5bf8-4807-c0e5-5fcad4adb93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "cell_type": "code",
      "source": [
        "df.WHO.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DEADPOOL            217\n",
              "WADE                151\n",
              "VANESSA              62\n",
              "WEASEL               60\n",
              "FRANCIS              55\n",
              "COLOSSUS             36\n",
              "DOPINDER             26\n",
              "AL                   21\n",
              "MAN                  19\n",
              "NEGASONIC            16\n",
              "MERCHANT              8\n",
              "JEREMY                7\n",
              "ANGEL                 7\n",
              "CUNNINGHAM            6\n",
              "MERC                  4\n",
              "REPORTER              2\n",
              "MEGAN                 2\n",
              "BOB                   2\n",
              "DJ                    2\n",
              "DOCTOR                2\n",
              "ARCADE EMPLOYEE       1\n",
              "DOPINDER'S VOICE      1\n",
              "DEAPOOL               1\n",
              "GIRL                  1\n",
              "Name: WHO, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "FUCKc9mRSz_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.WHO[df.WHO==\"DEAPOOL\"]=\"DEADPOOL\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUvsLHzHS-17",
        "colab_type": "code",
        "outputId": "a2dd244c-df6a-40de-cb59-55e50c26be25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "cell_type": "code",
      "source": [
        "df.WHO.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DEADPOOL            218\n",
              "WADE                151\n",
              "VANESSA              62\n",
              "WEASEL               60\n",
              "FRANCIS              55\n",
              "COLOSSUS             36\n",
              "DOPINDER             26\n",
              "AL                   21\n",
              "MAN                  19\n",
              "NEGASONIC            16\n",
              "MERCHANT              8\n",
              "JEREMY                7\n",
              "ANGEL                 7\n",
              "CUNNINGHAM            6\n",
              "MERC                  4\n",
              "DOCTOR                2\n",
              "REPORTER              2\n",
              "BOB                   2\n",
              "MEGAN                 2\n",
              "DJ                    2\n",
              "ARCADE EMPLOYEE       1\n",
              "DOPINDER'S VOICE      1\n",
              "GIRL                  1\n",
              "Name: WHO, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "djItgtuuSdBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove punctuation"
      ]
    },
    {
      "metadata": {
        "id": "yFkvqQOGVEst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "remove_punct_map=dict.fromkeys(map(ord, string.punctuation))\n",
        "df['TEXT_lower']=df['TEXT'].apply(\n",
        "  lambda x: ' '.join(x.lower().translate(remove_punct_map) for x in x.split()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmsTDPBCWIHz",
        "colab_type": "code",
        "outputId": "64460984-38e7-46d4-efb9-35e89a64e69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>TEXT_lower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Kinda lonesome back here.</td>\n",
              "      <td>kinda lonesome back here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Little help?</td>\n",
              "      <td>little help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Sir, I have to keep my hands on the wheel.</td>\n",
              "      <td>sir i have to keep my hands on the wheel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Excuse me.</td>\n",
              "      <td>excuse me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Dopinder.</td>\n",
              "      <td>dopinder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                                         TEXT  \\\n",
              "0  DEADPOOL                    Kinda lonesome back here.   \n",
              "1  DEADPOOL                                 Little help?   \n",
              "2  DOPINDER   Sir, I have to keep my hands on the wheel.   \n",
              "3  DEADPOOL                                   Excuse me.   \n",
              "4  DOPINDER                                    Dopinder.   \n",
              "\n",
              "                                 TEXT_lower  \n",
              "0                  kinda lonesome back here  \n",
              "1                               little help  \n",
              "2  sir i have to keep my hands on the wheel  \n",
              "3                                 excuse me  \n",
              "4                                  dopinder  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "oTpksnYOSkFW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove digits"
      ]
    },
    {
      "metadata": {
        "id": "ot_HVXF9W8kC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "remove_digit_map=dict.fromkeys(map(ord,string.digits))\n",
        "df['TEXT2']=[s.translate(remove_digit_map) for s in df[\"TEXT_lower\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65m-TwCoW8nT",
        "colab_type": "code",
        "outputId": "7239c742-e01e-465c-ec07-f91da716d59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>TEXT_lower</th>\n",
              "      <th>TEXT2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Kinda lonesome back here.</td>\n",
              "      <td>kinda lonesome back here</td>\n",
              "      <td>kinda lonesome back here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Little help?</td>\n",
              "      <td>little help</td>\n",
              "      <td>little help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Sir, I have to keep my hands on the wheel.</td>\n",
              "      <td>sir i have to keep my hands on the wheel</td>\n",
              "      <td>sir i have to keep my hands on the wheel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>Excuse me.</td>\n",
              "      <td>excuse me</td>\n",
              "      <td>excuse me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>Dopinder.</td>\n",
              "      <td>dopinder</td>\n",
              "      <td>dopinder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                                         TEXT  \\\n",
              "0  DEADPOOL                    Kinda lonesome back here.   \n",
              "1  DEADPOOL                                 Little help?   \n",
              "2  DOPINDER   Sir, I have to keep my hands on the wheel.   \n",
              "3  DEADPOOL                                   Excuse me.   \n",
              "4  DOPINDER                                    Dopinder.   \n",
              "\n",
              "                                 TEXT_lower  \\\n",
              "0                  kinda lonesome back here   \n",
              "1                               little help   \n",
              "2  sir i have to keep my hands on the wheel   \n",
              "3                                 excuse me   \n",
              "4                                  dopinder   \n",
              "\n",
              "                                      TEXT2  \n",
              "0                  kinda lonesome back here  \n",
              "1                               little help  \n",
              "2  sir i have to keep my hands on the wheel  \n",
              "3                                 excuse me  \n",
              "4                                  dopinder  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "g14d8llRW8rB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[['WHO','TEXT2']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCIJsanoY7qp",
        "colab_type": "code",
        "outputId": "099b3797-e7e6-4f19-a2fb-8a3c79ccfd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>kinda lonesome back here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>little help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>sir i have to keep my hands on the wheel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>excuse me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>dopinder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                                     TEXT2\n",
              "0  DEADPOOL                  kinda lonesome back here\n",
              "1  DEADPOOL                               little help\n",
              "2  DOPINDER  sir i have to keep my hands on the wheel\n",
              "3  DEADPOOL                                 excuse me\n",
              "4  DOPINDER                                  dopinder"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "siUG0LdGYSTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " df=df.rename(columns={\"TEXT2\": \"TEXT\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORXa9NFKW8uN",
        "colab_type": "code",
        "outputId": "72f636b0-75f8-4475-820f-968390df2946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>kinda lonesome back here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>little help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>sir i have to keep my hands on the wheel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>excuse me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOPINDER</td>\n",
              "      <td>dopinder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                                      TEXT\n",
              "0  DEADPOOL                  kinda lonesome back here\n",
              "1  DEADPOOL                               little help\n",
              "2  DOPINDER  sir i have to keep my hands on the wheel\n",
              "3  DEADPOOL                                 excuse me\n",
              "4  DOPINDER                                  dopinder"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "-NBPi8WrStRy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove stopwords"
      ]
    },
    {
      "metadata": {
        "id": "s7Jut38WdKfV",
        "colab_type": "code",
        "outputId": "0058c588-1359-44be-966b-603f2edeeced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "df['TEXT'] = df['TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kxy83Fq3d-3K",
        "colab_type": "code",
        "outputId": "791a22c4-b54f-44c5-bc77-e95ed65b3d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>looks everything ever heard david beckham spea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>find find im going get angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>WADE</td>\n",
              "      <td>ah nope nope nope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>MAN</td>\n",
              "      <td>youre looking alive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>WEASEL</td>\n",
              "      <td>put money realized im never going win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>VANESSA</td>\n",
              "      <td>get</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>youre still go home oh youre expecting teaser ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>WADE</td>\n",
              "      <td>id say sound like infomercial good one like sl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>WADE</td>\n",
              "      <td>m’lady</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>WADE</td>\n",
              "      <td>promise youll right right someone else</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WHO                                               TEXT\n",
              "516  DEADPOOL  looks everything ever heard david beckham spea...\n",
              "553  DEADPOOL                       find find im going get angry\n",
              "212      WADE                                  ah nope nope nope\n",
              "464       MAN                                youre looking alive\n",
              "452    WEASEL              put money realized im never going win\n",
              "188   VANESSA                                                get\n",
              "708  DEADPOOL  youre still go home oh youre expecting teaser ...\n",
              "305      WADE  id say sound like infomercial good one like sl...\n",
              "200      WADE                                             m’lady\n",
              "366      WADE             promise youll right right someone else"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "4ijV45axS3wO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ]
    },
    {
      "metadata": {
        "id": "-4JMTSFzKLvX",
        "colab_type": "code",
        "outputId": "6582cce5-daf1-42e1-800f-a4da3f3bcc34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "vdfDThVNdKnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['tokenized_sentences'] = df['TEXT'].apply(word_tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "238gmS8_dKvY",
        "colab_type": "code",
        "outputId": "daa0e46c-5090-4c33-e94d-ccc914ea675c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>WEASEL</td>\n",
              "      <td>saw head back go get tiger</td>\n",
              "      <td>[saw, head, back, go, get, tiger]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>hope youre watching</td>\n",
              "      <td>[hope, youre, watching]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>MAN</td>\n",
              "      <td>spend days sticking little people</td>\n",
              "      <td>[spend, days, sticking, little, people]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>MERCHANT</td>\n",
              "      <td>didn’t know scared</td>\n",
              "      <td>[didn, ’, t, know, scared]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>yoohoo oh god awe</td>\n",
              "      <td>[yoohoo, oh, god, awe]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>VANESSA</td>\n",
              "      <td>year dog</td>\n",
              "      <td>[year, dog]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>know second felt like three mini lion robots c...</td>\n",
              "      <td>[know, second, felt, like, three, mini, lion, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>lets recap cockthistle turned freak slipped ar...</td>\n",
              "      <td>[lets, recap, cockthistle, turned, freak, slip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>ass mean im proud</td>\n",
              "      <td>[ass, mean, im, proud]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>WADE</td>\n",
              "      <td>rough childhood</td>\n",
              "      <td>[rough, childhood]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WHO                                               TEXT  \\\n",
              "550    WEASEL                         saw head back go get tiger   \n",
              "342  DEADPOOL                                hope youre watching   \n",
              "302       MAN                  spend days sticking little people   \n",
              "111  MERCHANT                                 didn’t know scared   \n",
              "658  DEADPOOL                                  yoohoo oh god awe   \n",
              "210   VANESSA                                           year dog   \n",
              "702  DEADPOOL  know second felt like three mini lion robots c...   \n",
              "502  DEADPOOL  lets recap cockthistle turned freak slipped ar...   \n",
              "700  DEADPOOL                                  ass mean im proud   \n",
              "172      WADE                                    rough childhood   \n",
              "\n",
              "                                   tokenized_sentences  \n",
              "550                  [saw, head, back, go, get, tiger]  \n",
              "342                            [hope, youre, watching]  \n",
              "302            [spend, days, sticking, little, people]  \n",
              "111                         [didn, ’, t, know, scared]  \n",
              "658                             [yoohoo, oh, god, awe]  \n",
              "210                                        [year, dog]  \n",
              "702  [know, second, felt, like, three, mini, lion, ...  \n",
              "502  [lets, recap, cockthistle, turned, freak, slip...  \n",
              "700                             [ass, mean, im, proud]  \n",
              "172                                 [rough, childhood]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "v-ZslFLrT1P6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get Wade's and Deadpool's text"
      ]
    },
    {
      "metadata": {
        "id": "hU6pt7f2TECR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "names = [\"DEADPOOL\", \"WADE\"]\n",
        "dp_all=df[df.WHO.isin(names)]\n",
        "dp=df[df.WHO==\"DEADPOOL\"]\n",
        "wade=df[df.WHO==\"WADE\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8krqxDCsVSoH",
        "colab_type": "code",
        "outputId": "af15ebcf-ad96-4a83-87be-9ba0cc0e493f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "wade.head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>WADE</td>\n",
              "      <td>pineapple olive sweet salty</td>\n",
              "      <td>[pineapple, olive, sweet, salty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>WADE</td>\n",
              "      <td>bread crust</td>\n",
              "      <td>[bread, crust]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>WADE</td>\n",
              "      <td>thanks</td>\n",
              "      <td>[thanks]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>WADE</td>\n",
              "      <td>jeremy wade wilson ah go tiperoo jer i’m i’m</td>\n",
              "      <td>[jeremy, wade, wilson, ah, go, tiperoo, jer, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>WADE</td>\n",
              "      <td>you’re woods yet need seriously easeup bedazzl...</td>\n",
              "      <td>[you, ’, re, woods, yet, need, seriously, ease...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     WHO                                               TEXT  \\\n",
              "86  WADE                        pineapple olive sweet salty   \n",
              "88  WADE                                        bread crust   \n",
              "91  WADE                                             thanks   \n",
              "93  WADE       jeremy wade wilson ah go tiperoo jer i’m i’m   \n",
              "95  WADE  you’re woods yet need seriously easeup bedazzl...   \n",
              "\n",
              "                                  tokenized_sentences  \n",
              "86                   [pineapple, olive, sweet, salty]  \n",
              "88                                     [bread, crust]  \n",
              "91                                           [thanks]  \n",
              "93  [jeremy, wade, wilson, ah, go, tiperoo, jer, i...  \n",
              "95  [you, ’, re, woods, yet, need, seriously, ease...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "aJEp4E4mec5k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#dp_all['TEXT'] = dp_all['TEXT'].str.replace('narrating', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJSYzPd4UNzI",
        "colab_type": "code",
        "outputId": "142de2f6-deea-4a80-fb40-60eeeb9f486e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Deadpool's dialoques: \")\n",
        "len(dp)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deadpool's dialoques: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "H-2T8iwzUhWV",
        "colab_type": "code",
        "outputId": "86b27d61-9f44-4a47-d73b-026f63c3f020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Wade's dialoques: \")\n",
        "len(wade)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wade's dialoques: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "3NEpp9JbUDd-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ]
    },
    {
      "metadata": {
        "id": "OHvijx2w1EO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzA-4vgO29Bf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "snowball_stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P65F_xXopvxd",
        "colab_type": "code",
        "outputId": "0beeaa36-5963-4719-ef2b-3f02b1e2ce5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all['stemmed2']=dp_all['tokenized_sentences'].apply(lambda x : [    lancaster_stemmer.stem(y) for y in x])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Htg8tYppv6I",
        "colab_type": "code",
        "outputId": "2f000763-bc75-48bc-906b-695a7f223246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "dp_all['stemmed3']=dp_all['tokenized_sentences'].apply(lambda x : [snowball_stemmer.stem(y) for y in x])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ougYZ5c_1D95",
        "colab_type": "code",
        "outputId": "d6b2c5f1-5316-4fdf-979e-c1ef8f6f90fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "      <th>stemmed2</th>\n",
              "      <th>stemmed3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>kinda lonesome back</td>\n",
              "      <td>[kinda, lonesome, back]</td>\n",
              "      <td>[kind, lonesom, back]</td>\n",
              "      <td>[kinda, lonesom, back]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>little help</td>\n",
              "      <td>[little, help]</td>\n",
              "      <td>[littl, help]</td>\n",
              "      <td>[littl, help]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>excuse</td>\n",
              "      <td>[excuse]</td>\n",
              "      <td>[excus]</td>\n",
              "      <td>[excus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>pool dead</td>\n",
              "      <td>[pool, dead]</td>\n",
              "      <td>[pool, dead]</td>\n",
              "      <td>[pool, dead]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>mmm nice</td>\n",
              "      <td>[mmm, nice]</td>\n",
              "      <td>[mmm, nic]</td>\n",
              "      <td>[mmm, nice]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        WHO                 TEXT      tokenized_sentences  \\\n",
              "0  DEADPOOL  kinda lonesome back  [kinda, lonesome, back]   \n",
              "1  DEADPOOL          little help           [little, help]   \n",
              "3  DEADPOOL               excuse                 [excuse]   \n",
              "5  DEADPOOL            pool dead             [pool, dead]   \n",
              "6  DEADPOOL             mmm nice              [mmm, nice]   \n",
              "\n",
              "                stemmed2                stemmed3  \n",
              "0  [kind, lonesom, back]  [kinda, lonesom, back]  \n",
              "1          [littl, help]           [littl, help]  \n",
              "3                [excus]                 [excus]  \n",
              "5           [pool, dead]            [pool, dead]  \n",
              "6             [mmm, nic]             [mmm, nice]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "u7ZWorFJUMtP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ]
    },
    {
      "metadata": {
        "id": "EypT6bpU3ogR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoItonLOrlE5",
        "colab_type": "code",
        "outputId": "adaa5cbb-179f-49cd-ad2a-7be210c93059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "zZiR1N_GqzQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wnl = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9Xm2XoJ4aLN",
        "colab_type": "code",
        "outputId": "437abf82-baee-49b1-a59b-e93edc0daf37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all['lemmatized']=dp_all['tokenized_sentences'].apply(lambda x : [wnl.lemmatize(y) for y in x])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtL74w8bf8ZF",
        "colab_type": "code",
        "outputId": "6df62366-0158-480a-9a01-a21054a33ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all.sample(20)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "      <th>stemmed2</th>\n",
              "      <th>stemmed3</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>WADE</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>well think youre pretty darn cute</td>\n",
              "      <td>[well, think, youre, pretty, darn, cute]</td>\n",
              "      <td>[wel, think, yo, pretty, darn, cut]</td>\n",
              "      <td>[well, think, your, pretti, darn, cute]</td>\n",
              "      <td>[well, think, youre, pretty, darn, cute]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>sorry bleeding garbage seltzer water lemon blo...</td>\n",
              "      <td>[sorry, bleeding, garbage, seltzer, water, lem...</td>\n",
              "      <td>[sorry, blee, garb, seltz, wat, lemon, blood, ...</td>\n",
              "      <td>[sorri, bleed, garbag, seltzer, water, lemon, ...</td>\n",
              "      <td>[sorry, bleeding, garbage, seltzer, water, lem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>WADE</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>please anythings improvement holdall id taken ...</td>\n",
              "      <td>[please, anythings, improvement, holdall, id, ...</td>\n",
              "      <td>[pleas, anyth, improv, holdal, id, tak, em, tr...</td>\n",
              "      <td>[pleas, anyth, improv, holdal, id, taken, em, ...</td>\n",
              "      <td>[please, anythings, improvement, holdall, id, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>oh poor wife</td>\n",
              "      <td>[oh, poor, wife]</td>\n",
              "      <td>[oh, poor, wif]</td>\n",
              "      <td>[oh, poor, wife]</td>\n",
              "      <td>[oh, poor, wife]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>WADE</td>\n",
              "      <td>year</td>\n",
              "      <td>[year]</td>\n",
              "      <td>[year]</td>\n",
              "      <td>[year]</td>\n",
              "      <td>[year]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>need guns</td>\n",
              "      <td>[need, guns]</td>\n",
              "      <td>[nee, gun]</td>\n",
              "      <td>[need, gun]</td>\n",
              "      <td>[need, gun]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>hashtag drive</td>\n",
              "      <td>[hashtag, drive]</td>\n",
              "      <td>[hasht, driv]</td>\n",
              "      <td>[hashtag, drive]</td>\n",
              "      <td>[hashtag, drive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>yeah</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>dont worry baby im coming</td>\n",
              "      <td>[dont, worry, baby, im, coming]</td>\n",
              "      <td>[dont, worry, baby, im, com]</td>\n",
              "      <td>[dont, worri, babi, im, come]</td>\n",
              "      <td>[dont, worry, baby, im, coming]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>WADE</td>\n",
              "      <td>el cancer</td>\n",
              "      <td>[el, cancer]</td>\n",
              "      <td>[el, cant]</td>\n",
              "      <td>[el, cancer]</td>\n",
              "      <td>[el, cancer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>WADE</td>\n",
              "      <td>ugh thought guys dicks</td>\n",
              "      <td>[ugh, thought, guys, dicks]</td>\n",
              "      <td>[ugh, thought, guy, dick]</td>\n",
              "      <td>[ugh, thought, guy, dick]</td>\n",
              "      <td>[ugh, thought, guy, dick]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>im gonna wait till arm plows puberty im gonna ...</td>\n",
              "      <td>[im, gon, na, wait, till, arm, plows, puberty,...</td>\n",
              "      <td>[im, gon, na, wait, til, arm, plow, puberty, i...</td>\n",
              "      <td>[im, gon, na, wait, till, arm, plow, puberti, ...</td>\n",
              "      <td>[im, gon, na, wait, till, arm, plow, puberty, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>WADE</td>\n",
              "      <td>kay we’re cool</td>\n",
              "      <td>[kay, we, ’, re, cool]</td>\n",
              "      <td>[kay, we, ’, re, cool]</td>\n",
              "      <td>[kay, we, ’, re, cool]</td>\n",
              "      <td>[kay, we, ’, re, cool]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>WADE</td>\n",
              "      <td>turn service</td>\n",
              "      <td>[turn, service]</td>\n",
              "      <td>[turn, serv]</td>\n",
              "      <td>[turn, servic]</td>\n",
              "      <td>[turn, service]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>woo superhero landing know thats really hard k...</td>\n",
              "      <td>[woo, superhero, landing, know, thats, really,...</td>\n",
              "      <td>[woo, superhero, land, know, that, real, hard,...</td>\n",
              "      <td>[woo, superhero, land, know, that, realli, har...</td>\n",
              "      <td>[woo, superhero, landing, know, thats, really,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>WADE</td>\n",
              "      <td>arent little strong lady im calling wang whats...</td>\n",
              "      <td>[arent, little, strong, lady, im, calling, wan...</td>\n",
              "      <td>[ar, littl, strong, lady, im, cal, wang, what,...</td>\n",
              "      <td>[arent, littl, strong, ladi, im, call, wang, w...</td>\n",
              "      <td>[arent, little, strong, lady, im, calling, wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>ah right main street</td>\n",
              "      <td>[ah, right, main, street]</td>\n",
              "      <td>[ah, right, main, street]</td>\n",
              "      <td>[ah, right, main, street]</td>\n",
              "      <td>[ah, right, main, street]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>WADE</td>\n",
              "      <td>fuck wrong</td>\n",
              "      <td>[fuck, wrong]</td>\n",
              "      <td>[fuck, wrong]</td>\n",
              "      <td>[fuck, wrong]</td>\n",
              "      <td>[fuck, wrong]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WHO                                               TEXT  \\\n",
              "439      WADE                                                      \n",
              "593  DEADPOOL                  well think youre pretty darn cute   \n",
              "477  DEADPOOL  sorry bleeding garbage seltzer water lemon blo...   \n",
              "132      WADE                                                      \n",
              "493  DEADPOOL  please anythings improvement holdall id taken ...   \n",
              "348  DEADPOOL                                       oh poor wife   \n",
              "207      WADE                                               year   \n",
              "557  DEADPOOL                                          need guns   \n",
              "503  DEADPOOL                                      hashtag drive   \n",
              "694  DEADPOOL                                               yeah   \n",
              "638  DEADPOOL                          dont worry baby im coming   \n",
              "289      WADE                                          el cancer   \n",
              "406      WADE                             ugh thought guys dicks   \n",
              "520  DEADPOOL  im gonna wait till arm plows puberty im gonna ...   \n",
              "107      WADE                                     kay we’re cool   \n",
              "374      WADE                                       turn service   \n",
              "615  DEADPOOL  woo superhero landing know thats really hard k...   \n",
              "371      WADE  arent little strong lady im calling wang whats...   \n",
              "74   DEADPOOL                               ah right main street   \n",
              "408      WADE                                         fuck wrong   \n",
              "\n",
              "                                   tokenized_sentences  \\\n",
              "439                                                 []   \n",
              "593           [well, think, youre, pretty, darn, cute]   \n",
              "477  [sorry, bleeding, garbage, seltzer, water, lem...   \n",
              "132                                                 []   \n",
              "493  [please, anythings, improvement, holdall, id, ...   \n",
              "348                                   [oh, poor, wife]   \n",
              "207                                             [year]   \n",
              "557                                       [need, guns]   \n",
              "503                                   [hashtag, drive]   \n",
              "694                                             [yeah]   \n",
              "638                    [dont, worry, baby, im, coming]   \n",
              "289                                       [el, cancer]   \n",
              "406                        [ugh, thought, guys, dicks]   \n",
              "520  [im, gon, na, wait, till, arm, plows, puberty,...   \n",
              "107                             [kay, we, ’, re, cool]   \n",
              "374                                    [turn, service]   \n",
              "615  [woo, superhero, landing, know, thats, really,...   \n",
              "371  [arent, little, strong, lady, im, calling, wan...   \n",
              "74                           [ah, right, main, street]   \n",
              "408                                      [fuck, wrong]   \n",
              "\n",
              "                                              stemmed2  \\\n",
              "439                                                 []   \n",
              "593                [wel, think, yo, pretty, darn, cut]   \n",
              "477  [sorry, blee, garb, seltz, wat, lemon, blood, ...   \n",
              "132                                                 []   \n",
              "493  [pleas, anyth, improv, holdal, id, tak, em, tr...   \n",
              "348                                    [oh, poor, wif]   \n",
              "207                                             [year]   \n",
              "557                                         [nee, gun]   \n",
              "503                                      [hasht, driv]   \n",
              "694                                             [yeah]   \n",
              "638                       [dont, worry, baby, im, com]   \n",
              "289                                         [el, cant]   \n",
              "406                          [ugh, thought, guy, dick]   \n",
              "520  [im, gon, na, wait, til, arm, plow, puberty, i...   \n",
              "107                             [kay, we, ’, re, cool]   \n",
              "374                                       [turn, serv]   \n",
              "615  [woo, superhero, land, know, that, real, hard,...   \n",
              "371  [ar, littl, strong, lady, im, cal, wang, what,...   \n",
              "74                           [ah, right, main, street]   \n",
              "408                                      [fuck, wrong]   \n",
              "\n",
              "                                              stemmed3  \\\n",
              "439                                                 []   \n",
              "593            [well, think, your, pretti, darn, cute]   \n",
              "477  [sorri, bleed, garbag, seltzer, water, lemon, ...   \n",
              "132                                                 []   \n",
              "493  [pleas, anyth, improv, holdal, id, taken, em, ...   \n",
              "348                                   [oh, poor, wife]   \n",
              "207                                             [year]   \n",
              "557                                        [need, gun]   \n",
              "503                                   [hashtag, drive]   \n",
              "694                                             [yeah]   \n",
              "638                      [dont, worri, babi, im, come]   \n",
              "289                                       [el, cancer]   \n",
              "406                          [ugh, thought, guy, dick]   \n",
              "520  [im, gon, na, wait, till, arm, plow, puberti, ...   \n",
              "107                             [kay, we, ’, re, cool]   \n",
              "374                                     [turn, servic]   \n",
              "615  [woo, superhero, land, know, that, realli, har...   \n",
              "371  [arent, littl, strong, ladi, im, call, wang, w...   \n",
              "74                           [ah, right, main, street]   \n",
              "408                                      [fuck, wrong]   \n",
              "\n",
              "                                            lemmatized  \n",
              "439                                                 []  \n",
              "593           [well, think, youre, pretty, darn, cute]  \n",
              "477  [sorry, bleeding, garbage, seltzer, water, lem...  \n",
              "132                                                 []  \n",
              "493  [please, anythings, improvement, holdall, id, ...  \n",
              "348                                   [oh, poor, wife]  \n",
              "207                                             [year]  \n",
              "557                                        [need, gun]  \n",
              "503                                   [hashtag, drive]  \n",
              "694                                             [yeah]  \n",
              "638                    [dont, worry, baby, im, coming]  \n",
              "289                                       [el, cancer]  \n",
              "406                          [ugh, thought, guy, dick]  \n",
              "520  [im, gon, na, wait, till, arm, plow, puberty, ...  \n",
              "107                             [kay, we, ’, re, cool]  \n",
              "374                                    [turn, service]  \n",
              "615  [woo, superhero, landing, know, thats, really,...  \n",
              "371  [arent, little, strong, lady, im, calling, wan...  \n",
              "74                           [ah, right, main, street]  \n",
              "408                                      [fuck, wrong]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "8CAvf0dv2Afp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Words** **frequency** "
      ]
    },
    {
      "metadata": {
        "id": "7AHVx861ec2R",
        "colab_type": "code",
        "outputId": "9c01769c-bc65-40ea-fc58-aa34c91f2e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "freq = pd.Series(' '.join(dp_all['TEXT']).split()).value_counts()[:20]\n",
        "freq"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "like         44\n",
              "im           39\n",
              "oh           30\n",
              "go           28\n",
              "get          22\n",
              "yeah         21\n",
              "got          21\n",
              "gonna        20\n",
              "youre        18\n",
              "fuck         18\n",
              "one          18\n",
              "narrating    17\n",
              "know         17\n",
              "good         16\n",
              "wait         15\n",
              "right        15\n",
              "shit         15\n",
              "see          14\n",
              "francis      14\n",
              "time         14\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3ZprgSfouw7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "72312995-c213-4957-8024-458e2de80bc9"
      },
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "aB-ZrWlKs-Mk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "allWords = []\n",
        "for wordList in dp_all['tokenized_sentences']:\n",
        "    allWords += wordList\n",
        "fdist = FreqDist(allWords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZenH0pPXhr0y",
        "colab_type": "code",
        "outputId": "6f298801-fccc-4469-fa42-72e25ecc206c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "fdist.most_common(20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('’', 78),\n",
              " ('like', 44),\n",
              " ('im', 39),\n",
              " ('s', 36),\n",
              " ('oh', 30),\n",
              " ('go', 28),\n",
              " ('na', 28),\n",
              " ('got', 23),\n",
              " ('get', 22),\n",
              " ('yeah', 21),\n",
              " ('gon', 20),\n",
              " ('one', 18),\n",
              " ('fuck', 18),\n",
              " ('youre', 18),\n",
              " ('i', 17),\n",
              " ('know', 17),\n",
              " ('narrating', 17),\n",
              " ('good', 16),\n",
              " ('shit', 15),\n",
              " ('right', 15)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "1rLMpy3uhr4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fdist = FreqDist(brown.words())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oC-wMJjNec8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mostcommon = fdist.most_common(50)\n",
        "mclist = []\n",
        "for i in range(len(mostcommon)):\n",
        "    mclist.append(mostcommon[i][0])\n",
        "words = [w for w in dp_all['tokenized_sentences'] if w not in mclist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SdTWDo6yedCj",
        "colab_type": "code",
        "outputId": "c37a74f2-96ff-4465-ccc3-9922344c74f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "cell_type": "code",
      "source": [
        "mclist"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " ',',\n",
              " '.',\n",
              " 'of',\n",
              " 'and',\n",
              " 'to',\n",
              " 'a',\n",
              " 'in',\n",
              " 'that',\n",
              " 'is',\n",
              " 'was',\n",
              " 'for',\n",
              " '``',\n",
              " \"''\",\n",
              " 'The',\n",
              " 'with',\n",
              " 'it',\n",
              " 'as',\n",
              " 'he',\n",
              " 'his',\n",
              " 'on',\n",
              " 'be',\n",
              " ';',\n",
              " 'I',\n",
              " 'by',\n",
              " 'had',\n",
              " 'at',\n",
              " '?',\n",
              " 'not',\n",
              " 'are',\n",
              " 'from',\n",
              " 'or',\n",
              " 'this',\n",
              " 'have',\n",
              " 'an',\n",
              " 'which',\n",
              " '--',\n",
              " 'were',\n",
              " 'but',\n",
              " 'He',\n",
              " 'her',\n",
              " 'one',\n",
              " 'they',\n",
              " 'you',\n",
              " 'all',\n",
              " 'would',\n",
              " 'him',\n",
              " 'their',\n",
              " 'been',\n",
              " ')']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "oQ0ArdYzg9Ph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove most common words\n"
      ]
    },
    {
      "metadata": {
        "id": "jeiFz3MyfcB_",
        "colab_type": "code",
        "outputId": "727ad063-ef3f-4005-8940-1c57892044f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all['clean'] = dp_all['tokenized_sentences'].apply(lambda x: \" \".join(x for x in x if x not in mclist))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FefmLmACg1m5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remove short 2 characters long words"
      ]
    },
    {
      "metadata": {
        "id": "iM1F8uDNgY0d",
        "colab_type": "code",
        "outputId": "e3cfe40a-0722-48b8-88ee-52716bea7a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all['clean2'] = dp_all['clean'].str.split().map(lambda sl: \" \".join(s for s in sl if len(s) > 2))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fhudfjLja6C4",
        "colab_type": "code",
        "outputId": "24d17ae3-369b-4305-931c-0252154a4d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "cell_type": "code",
      "source": [
        "dp_all.sample(20\n",
        "             )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "      <th>stemmed2</th>\n",
              "      <th>stemmed3</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>clean</th>\n",
              "      <th>clean2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>WADE</td>\n",
              "      <td>youre right cancers liver lungs prostate brain...</td>\n",
              "      <td>[youre, right, cancers, liver, lungs, prostate...</td>\n",
              "      <td>[yo, right, cant, liv, lung, prost, brain, thi...</td>\n",
              "      <td>[your, right, cancer, liver, lung, prostat, br...</td>\n",
              "      <td>[youre, right, cancer, liver, lung, prostate, ...</td>\n",
              "      <td>youre right cancers liver lungs prostate brain...</td>\n",
              "      <td>youre right cancers liver lungs prostate brain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>guy already got</td>\n",
              "      <td>[guy, already, got]</td>\n",
              "      <td>[guy, already, got]</td>\n",
              "      <td>[guy, alreadi, got]</td>\n",
              "      <td>[guy, already, got]</td>\n",
              "      <td>guy already got</td>\n",
              "      <td>guy already got</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>still get go make useful go really big brother...</td>\n",
              "      <td>[still, get, go, make, useful, go, really, big...</td>\n",
              "      <td>[stil, get, go, mak, us, go, real, big, broth,...</td>\n",
              "      <td>[still, get, go, make, use, go, realli, big, b...</td>\n",
              "      <td>[still, get, go, make, useful, go, really, big...</td>\n",
              "      <td>still get go make useful go really big brother...</td>\n",
              "      <td>still get make useful really big brother someo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>sounds like last saturday night</td>\n",
              "      <td>[sounds, like, last, saturday, night]</td>\n",
              "      <td>[sound, lik, last, saturday, night]</td>\n",
              "      <td>[sound, like, last, saturday, night]</td>\n",
              "      <td>[sound, like, last, saturday, night]</td>\n",
              "      <td>sounds like last saturday night</td>\n",
              "      <td>sounds like last saturday night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>hey oh</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>hey oh</td>\n",
              "      <td>hey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>WADE</td>\n",
              "      <td>sadistic fuck</td>\n",
              "      <td>[sadistic, fuck]</td>\n",
              "      <td>[sad, fuck]</td>\n",
              "      <td>[sadist, fuck]</td>\n",
              "      <td>[sadistic, fuck]</td>\n",
              "      <td>sadistic fuck</td>\n",
              "      <td>sadistic fuck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>ha fake laugh hiding real pain go get silver b...</td>\n",
              "      <td>[ha, fake, laugh, hiding, real, pain, go, get,...</td>\n",
              "      <td>[ha, fak, laugh, hid, real, pain, go, get, sil...</td>\n",
              "      <td>[ha, fake, laugh, hide, real, pain, go, get, s...</td>\n",
              "      <td>[ha, fake, laugh, hiding, real, pain, go, get,...</td>\n",
              "      <td>ha fake laugh hiding real pain go get silver b...</td>\n",
              "      <td>fake laugh hiding real pain get silver balls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>WADE</td>\n",
              "      <td>we’re good together</td>\n",
              "      <td>[we, ’, re, good, together]</td>\n",
              "      <td>[we, ’, re, good, togeth]</td>\n",
              "      <td>[we, ’, re, good, togeth]</td>\n",
              "      <td>[we, ’, re, good, together]</td>\n",
              "      <td>we ’ re good together</td>\n",
              "      <td>good together</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>well know twelve</td>\n",
              "      <td>[well, know, twelve]</td>\n",
              "      <td>[wel, know, twelv]</td>\n",
              "      <td>[well, know, twelv]</td>\n",
              "      <td>[well, know, twelve]</td>\n",
              "      <td>well know twelve</td>\n",
              "      <td>well know twelve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>i’ve never said don’t swallow</td>\n",
              "      <td>[i, ’, ve, never, said, don, ’, t, swallow]</td>\n",
              "      <td>[i, ’, ve, nev, said, don, ’, t, swallow]</td>\n",
              "      <td>[i, ’, ve, never, said, don, ’, t, swallow]</td>\n",
              "      <td>[i, ’, ve, never, said, don, ’, t, swallow]</td>\n",
              "      <td>i ’ ve never said don ’ t swallow</td>\n",
              "      <td>never said don swallow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>WADE</td>\n",
              "      <td>jesus warmer table really come safe word fella...</td>\n",
              "      <td>[jesus, warmer, table, really, come, safe, wor...</td>\n",
              "      <td>[jes, warm, tabl, real, com, saf, word, fella,...</td>\n",
              "      <td>[jesus, warmer, tabl, realli, come, safe, word...</td>\n",
              "      <td>[jesus, warmer, table, really, come, safe, wor...</td>\n",
              "      <td>jesus warmer table really come safe word fella...</td>\n",
              "      <td>jesus warmer table really come safe word fella...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>that’s mostly money</td>\n",
              "      <td>[that, ’, s, mostly, money]</td>\n",
              "      <td>[that, ’, s, most, money]</td>\n",
              "      <td>[that, ’, s, most, money]</td>\n",
              "      <td>[that, ’, s, mostly, money]</td>\n",
              "      <td>’ s mostly money</td>\n",
              "      <td>mostly money</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>francis francis</td>\n",
              "      <td>[francis, francis]</td>\n",
              "      <td>[frant, frant]</td>\n",
              "      <td>[franci, franci]</td>\n",
              "      <td>[francis, francis]</td>\n",
              "      <td>francis francis</td>\n",
              "      <td>francis francis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>dont worry im totally top</td>\n",
              "      <td>[dont, worry, im, totally, top]</td>\n",
              "      <td>[dont, worry, im, tot, top]</td>\n",
              "      <td>[dont, worri, im, total, top]</td>\n",
              "      <td>[dont, worry, im, totally, top]</td>\n",
              "      <td>dont worry im totally top</td>\n",
              "      <td>dont worry totally top</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>WADE</td>\n",
              "      <td>guy fix fugly mug brown shitstick mutant facto...</td>\n",
              "      <td>[guy, fix, fugly, mug, brown, shitstick, mutan...</td>\n",
              "      <td>[guy, fix, fug, mug, brown, shitstick, mut, fa...</td>\n",
              "      <td>[guy, fix, fug, mug, brown, shitstick, mutant,...</td>\n",
              "      <td>[guy, fix, fugly, mug, brown, shitstick, mutan...</td>\n",
              "      <td>guy fix fugly mug brown shitstick mutant facto...</td>\n",
              "      <td>guy fix fugly mug brown shitstick mutant facto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>id stick stuck bactine raided stash wisdom tee...</td>\n",
              "      <td>[id, stick, stuck, bactine, raided, stash, wis...</td>\n",
              "      <td>[id, stick, stuck, bactin, raid, stash, wisdom...</td>\n",
              "      <td>[id, stick, stuck, bactin, raid, stash, wisdom...</td>\n",
              "      <td>[id, stick, stuck, bactine, raided, stash, wis...</td>\n",
              "      <td>id stick stuck bactine raided stash wisdom tee...</td>\n",
              "      <td>stick stuck bactine raided stash wisdom teeth ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>shit</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>shit</td>\n",
              "      <td>shit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>na na na na na lets go cough</td>\n",
              "      <td>[na, na, na, na, na, lets, go, cough]</td>\n",
              "      <td>[na, na, na, na, na, let, go, cough]</td>\n",
              "      <td>[na, na, na, na, na, let, go, cough]</td>\n",
              "      <td>[na, na, na, na, na, let, go, cough]</td>\n",
              "      <td>na na na na na lets go cough</td>\n",
              "      <td>lets cough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>WADE</td>\n",
              "      <td>dishwasher didn’t even go sleep pretty much ba...</td>\n",
              "      <td>[dishwasher, didn, ’, t, even, go, sleep, pret...</td>\n",
              "      <td>[dishwash, didn, ’, t, ev, go, sleep, pretty, ...</td>\n",
              "      <td>[dishwash, didn, ’, t, even, go, sleep, pretti...</td>\n",
              "      <td>[dishwasher, didn, ’, t, even, go, sleep, pret...</td>\n",
              "      <td>dishwasher didn ’ t even go sleep pretty much ...</td>\n",
              "      <td>dishwasher didn even sleep pretty much ball ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>WADE</td>\n",
              "      <td>narrating sorry francis lips sealed</td>\n",
              "      <td>[narrating, sorry, francis, lips, sealed]</td>\n",
              "      <td>[nar, sorry, frant, lip, seal]</td>\n",
              "      <td>[narrat, sorri, franci, lip, seal]</td>\n",
              "      <td>[narrating, sorry, francis, lip, sealed]</td>\n",
              "      <td>narrating sorry francis lips sealed</td>\n",
              "      <td>narrating sorry francis lips sealed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WHO                                               TEXT  \\\n",
              "273      WADE  youre right cancers liver lungs prostate brain...   \n",
              "333  DEADPOOL                                    guy already got   \n",
              "698  DEADPOOL  still get go make useful go really big brother...   \n",
              "652  DEADPOOL                    sounds like last saturday night   \n",
              "63   DEADPOOL                                             hey oh   \n",
              "417      WADE                                      sadistic fuck   \n",
              "582  DEADPOOL  ha fake laugh hiding real pain go get silver b...   \n",
              "224      WADE                                we’re good together   \n",
              "562  DEADPOOL                                   well know twelve   \n",
              "52   DEADPOOL                      i’ve never said don’t swallow   \n",
              "370      WADE  jesus warmer table really come safe word fella...   \n",
              "117  DEADPOOL                                that’s mostly money   \n",
              "77   DEADPOOL                                    francis francis   \n",
              "655  DEADPOOL                          dont worry im totally top   \n",
              "435      WADE  guy fix fugly mug brown shitstick mutant facto...   \n",
              "509  DEADPOOL  id stick stuck bactine raided stash wisdom tee...   \n",
              "67   DEADPOOL                                               shit   \n",
              "568  DEADPOOL                       na na na na na lets go cough   \n",
              "182      WADE  dishwasher didn’t even go sleep pretty much ba...   \n",
              "422      WADE                narrating sorry francis lips sealed   \n",
              "\n",
              "                                   tokenized_sentences  \\\n",
              "273  [youre, right, cancers, liver, lungs, prostate...   \n",
              "333                                [guy, already, got]   \n",
              "698  [still, get, go, make, useful, go, really, big...   \n",
              "652              [sounds, like, last, saturday, night]   \n",
              "63                                           [hey, oh]   \n",
              "417                                   [sadistic, fuck]   \n",
              "582  [ha, fake, laugh, hiding, real, pain, go, get,...   \n",
              "224                        [we, ’, re, good, together]   \n",
              "562                               [well, know, twelve]   \n",
              "52         [i, ’, ve, never, said, don, ’, t, swallow]   \n",
              "370  [jesus, warmer, table, really, come, safe, wor...   \n",
              "117                        [that, ’, s, mostly, money]   \n",
              "77                                  [francis, francis]   \n",
              "655                    [dont, worry, im, totally, top]   \n",
              "435  [guy, fix, fugly, mug, brown, shitstick, mutan...   \n",
              "509  [id, stick, stuck, bactine, raided, stash, wis...   \n",
              "67                                              [shit]   \n",
              "568              [na, na, na, na, na, lets, go, cough]   \n",
              "182  [dishwasher, didn, ’, t, even, go, sleep, pret...   \n",
              "422          [narrating, sorry, francis, lips, sealed]   \n",
              "\n",
              "                                              stemmed2  \\\n",
              "273  [yo, right, cant, liv, lung, prost, brain, thi...   \n",
              "333                                [guy, already, got]   \n",
              "698  [stil, get, go, mak, us, go, real, big, broth,...   \n",
              "652                [sound, lik, last, saturday, night]   \n",
              "63                                           [hey, oh]   \n",
              "417                                        [sad, fuck]   \n",
              "582  [ha, fak, laugh, hid, real, pain, go, get, sil...   \n",
              "224                          [we, ’, re, good, togeth]   \n",
              "562                                 [wel, know, twelv]   \n",
              "52           [i, ’, ve, nev, said, don, ’, t, swallow]   \n",
              "370  [jes, warm, tabl, real, com, saf, word, fella,...   \n",
              "117                          [that, ’, s, most, money]   \n",
              "77                                      [frant, frant]   \n",
              "655                        [dont, worry, im, tot, top]   \n",
              "435  [guy, fix, fug, mug, brown, shitstick, mut, fa...   \n",
              "509  [id, stick, stuck, bactin, raid, stash, wisdom...   \n",
              "67                                              [shit]   \n",
              "568               [na, na, na, na, na, let, go, cough]   \n",
              "182  [dishwash, didn, ’, t, ev, go, sleep, pretty, ...   \n",
              "422                     [nar, sorry, frant, lip, seal]   \n",
              "\n",
              "                                              stemmed3  \\\n",
              "273  [your, right, cancer, liver, lung, prostat, br...   \n",
              "333                                [guy, alreadi, got]   \n",
              "698  [still, get, go, make, use, go, realli, big, b...   \n",
              "652               [sound, like, last, saturday, night]   \n",
              "63                                           [hey, oh]   \n",
              "417                                     [sadist, fuck]   \n",
              "582  [ha, fake, laugh, hide, real, pain, go, get, s...   \n",
              "224                          [we, ’, re, good, togeth]   \n",
              "562                                [well, know, twelv]   \n",
              "52         [i, ’, ve, never, said, don, ’, t, swallow]   \n",
              "370  [jesus, warmer, tabl, realli, come, safe, word...   \n",
              "117                          [that, ’, s, most, money]   \n",
              "77                                    [franci, franci]   \n",
              "655                      [dont, worri, im, total, top]   \n",
              "435  [guy, fix, fug, mug, brown, shitstick, mutant,...   \n",
              "509  [id, stick, stuck, bactin, raid, stash, wisdom...   \n",
              "67                                              [shit]   \n",
              "568               [na, na, na, na, na, let, go, cough]   \n",
              "182  [dishwash, didn, ’, t, even, go, sleep, pretti...   \n",
              "422                 [narrat, sorri, franci, lip, seal]   \n",
              "\n",
              "                                            lemmatized  \\\n",
              "273  [youre, right, cancer, liver, lung, prostate, ...   \n",
              "333                                [guy, already, got]   \n",
              "698  [still, get, go, make, useful, go, really, big...   \n",
              "652               [sound, like, last, saturday, night]   \n",
              "63                                           [hey, oh]   \n",
              "417                                   [sadistic, fuck]   \n",
              "582  [ha, fake, laugh, hiding, real, pain, go, get,...   \n",
              "224                        [we, ’, re, good, together]   \n",
              "562                               [well, know, twelve]   \n",
              "52         [i, ’, ve, never, said, don, ’, t, swallow]   \n",
              "370  [jesus, warmer, table, really, come, safe, wor...   \n",
              "117                        [that, ’, s, mostly, money]   \n",
              "77                                  [francis, francis]   \n",
              "655                    [dont, worry, im, totally, top]   \n",
              "435  [guy, fix, fugly, mug, brown, shitstick, mutan...   \n",
              "509  [id, stick, stuck, bactine, raided, stash, wis...   \n",
              "67                                              [shit]   \n",
              "568               [na, na, na, na, na, let, go, cough]   \n",
              "182  [dishwasher, didn, ’, t, even, go, sleep, pret...   \n",
              "422           [narrating, sorry, francis, lip, sealed]   \n",
              "\n",
              "                                                 clean  \\\n",
              "273  youre right cancers liver lungs prostate brain...   \n",
              "333                                    guy already got   \n",
              "698  still get go make useful go really big brother...   \n",
              "652                    sounds like last saturday night   \n",
              "63                                              hey oh   \n",
              "417                                      sadistic fuck   \n",
              "582  ha fake laugh hiding real pain go get silver b...   \n",
              "224                              we ’ re good together   \n",
              "562                                   well know twelve   \n",
              "52                   i ’ ve never said don ’ t swallow   \n",
              "370  jesus warmer table really come safe word fella...   \n",
              "117                                   ’ s mostly money   \n",
              "77                                     francis francis   \n",
              "655                          dont worry im totally top   \n",
              "435  guy fix fugly mug brown shitstick mutant facto...   \n",
              "509  id stick stuck bactine raided stash wisdom tee...   \n",
              "67                                                shit   \n",
              "568                       na na na na na lets go cough   \n",
              "182  dishwasher didn ’ t even go sleep pretty much ...   \n",
              "422                narrating sorry francis lips sealed   \n",
              "\n",
              "                                                clean2  \n",
              "273  youre right cancers liver lungs prostate brain...  \n",
              "333                                    guy already got  \n",
              "698  still get make useful really big brother someo...  \n",
              "652                    sounds like last saturday night  \n",
              "63                                                 hey  \n",
              "417                                      sadistic fuck  \n",
              "582       fake laugh hiding real pain get silver balls  \n",
              "224                                      good together  \n",
              "562                                   well know twelve  \n",
              "52                              never said don swallow  \n",
              "370  jesus warmer table really come safe word fella...  \n",
              "117                                       mostly money  \n",
              "77                                     francis francis  \n",
              "655                             dont worry totally top  \n",
              "435  guy fix fugly mug brown shitstick mutant facto...  \n",
              "509  stick stuck bactine raided stash wisdom teeth ...  \n",
              "67                                                shit  \n",
              "568                                         lets cough  \n",
              "182  dishwasher didn even sleep pretty much ball ga...  \n",
              "422                narrating sorry francis lips sealed  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "SRnjItG905ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzWnCQnJcox4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Part of speech tagging (POS)"
      ]
    },
    {
      "metadata": {
        "id": "J5lNcUpN05fx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iq5AUqF5WW2t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create feature vectors "
      ]
    },
    {
      "metadata": {
        "id": "SRvG3evqWE-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e3cf066-5816-4c0a-ad14-72fe394f9f29"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(dp_all[\"clean2\"]) # learn the vocabulary dictionary and return a Document-Term matrix\n",
        "X_train_counts.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369, 1289)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "NsRMRxW8Wtsw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TF-IDF?\n",
        "TF: Just counting the number of words in each document has 1 issue: it will give more weightage to longer documents than shorter documents. To avoid this, we can use frequency (TF - Term Frequencies) i.e. #count(word) / #Total words, in each document.\n",
        "TF-IDF: Finally, we can even reduce the weightage of more common words like (the, is, an etc.) which occurs in all document. This is called as TF-IDF i.e Term Frequency times inverse document frequency."
      ]
    },
    {
      "metadata": {
        "id": "ZN-0p8unWQ1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9122dfe1-4e21-4b1a-8fa2-390518bdf19c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369, 1289)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "q7K8SFeKWQym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "26A0Xsira4px",
        "colab_type": "code",
        "outputId": "b6479aa3-6f2f-47da-9e90-99b38b2a9c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print('Vocabulary: ')\n",
        "print(count_vect.vocabulary_)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary: \n",
            "{'kinda': 578, 'lonesome': 637, 'back': 59, 'little': 631, 'help': 499, 'excuse': 354, 'pool': 833, 'dead': 272, 'mmm': 709, 'nice': 752, 'daffodil': 263, 'daydream': 270, 'girl': 449, 'dopinder': 311, 'starting': 1052, 'think': 1122, 'there': 1116, 'reason': 876, 'cab': 147, 'today': 1136, 'slender': 1009, 'brown': 134, 'friend': 417, 'love': 646, 'beautiful': 77, 'thing': 1120, 'find': 386, 'whole': 1232, 'world': 1259, 'tastes': 1097, 'like': 620, 'got': 462, 'hold': 510, 'onto': 779, 'tight': 1129, 'never': 748, 'let': 612, 'don': 308, 'make': 660, 'mistakes': 706, 'else': 333, 'mama': 662, 'june': 558, 'hot': 520, 'yoga': 1280, 'two': 1169, 'hobos': 509, 'fucking': 424, 'shoe': 981, 'filled': 384, 'piss': 822, 'day': 269, 'point': 831, 'bad': 61, 'christmas': 193, 'someone': 1022, 'naughty': 740, 'list': 627, 'waiting': 1190, 'year': 1275, 'three': 1127, 'weeks': 1214, 'six': 1000, 'days': 271, 'oh': 773, 'fourteen': 410, 'minutes': 703, 'fix': 392, 'shit': 972, 'boo': 109, 'forgot': 405, 'ammo': 27, 'bag': 62, 'nope': 761, 'time': 1132, 'fuck': 420, 'nine': 756, 'ten': 1107, 'eleven': 332, 'twelve': 1166, 'bullets': 140, 'bust': 145, 'carry': 164, 'wallet': 1192, 'working': 1258, 'ruins': 916, 'lines': 624, 'suit': 1073, 'bout': 119, 'crisp': 252, 'highfive': 507, 'merry': 692, 'wha': 1221, 'hello': 498, 'know': 585, 'right': 894, 'who': 1231, 'balls': 66, 'fondle': 401, 'get': 444, 'movie': 725, 'can': 154, 'tell': 1105, 'rhyme': 891, 'pullverine': 864, 'australian': 53, 'accent': 1, 'pair': 796, 'smooth': 1014, 'criminals': 251, 'anyway': 36, 'places': 827, 'face': 358, 'guys': 470, 'kill': 573, 'maximum': 675, 'effort': 329, 'rich': 893, 'corinthian': 238, 'leather': 603, 'looking': 640, 'francis': 413, 'seen': 949, 'man': 663, 'said': 923, 'swallow': 1083, 'leave': 604, 'stove': 1064, 'hey': 504, 'wait': 1189, 'may': 676, 'wondering': 1250, 'red': 878, 'well': 1217, 'see': 946, 'bleed': 101, 'guy': 469, 'idea': 528, 'wore': 1256, 'pants': 798, 'fine': 387, 'going': 456, 'share': 966, 'count': 242, 'mother': 721, 'fucker': 422, 'shoots': 984, 'misses': 705, 'eight': 330, 'deadpool': 274, 'seven': 961, 'good': 460, 'counting': 243, 'four': 409, 'main': 659, 'street': 1066, 'stupid': 1070, 'worth': 1264, 'ooh': 780, 'touching': 1146, 'tonight': 1139, 'biscuit': 94, 'ugh': 1171, 'really': 875, 'rolling': 905, 'sleeves': 1008, 'narrating': 739, 'probably': 851, 'thinking': 1123, 'boyfriend': 121, 'superhero': 1077, 'turned': 1164, 'kebab': 560, 'super': 1076, 'hero': 502, 'yeah': 1274, 'technically': 1102, 'murder': 731, 'best': 89, 'stories': 1062, 'start': 1051, 'exactly': 348, 'story': 1063, 'take': 1091, 'way': 1207, 'squeezed': 1045, 'ass': 48, 'spandex': 1030, 'pineapple': 821, 'olive': 776, 'sweet': 1086, 'salty': 925, 'bread': 124, 'crust': 254, 'thanks': 1112, 'jeremy': 549, 'wade': 1187, 'wilson': 1238, 'tiperoo': 1134, 'jer': 548, 'woods': 1253, 'yet': 1279, 'need': 742, 'seriously': 958, 'easeup': 325, 'bedazzling': 80, 'jeans': 547, 'chandelier': 175, 'keeping': 562, 'kind': 577, 'give': 452, 'shoot': 983, 'cat': 169, 'kitty': 580, 'litter': 630, 'anywho': 38, 'something': 1023, 'situation': 999, 'isn': 541, 'improved': 535, 'pizza': 825, 'happen': 478, 'megan': 686, 'orflowsky': 787, 'orlavsky': 789, 'orlovsky': 790, 'getting': 446, 'cause': 172, 'knows': 586, 'belong': 86, 'group': 466, 'dime': 295, 'beat': 76, 'fella': 380, 'she': 968, 'made': 657, 'money': 714, 'lucky': 651, 'soft': 1018, 'spot': 1042, 'stalker': 1046, 'threats': 1126, 'hurt': 526, 'nearly': 741, 'much': 728, 'serrated': 959, 'steel': 1055, 'keep': 561, 'away': 54, 'cool': 236, 'kay': 559, 'totally': 1145, 'done': 309, 'remember': 883, 'read': 873, 'book': 110, 'general': 438, 'direction': 299, 'learn': 601, 'worst': 1263, 'ways': 1208, 'hard': 483, 'spots': 1043, 'came': 151, 'wrong': 1268, 'shoulda': 988, 'brought': 133, 'roller': 904, 'blades': 100, 'show': 989, 'kids': 572, 'mostly': 720, 'pavement': 805, 'facial': 359, 'earned': 324, 'aint': 14, 'gets': 445, 'paid': 794, 'fuckup': 425, 'worse': 1262, 'welcome': 1216, 'sister': 997, 'margaret': 667, 'job': 553, 'fair': 361, 'mercenaries': 689, 'fucked': 421, 'tooth': 1140, 'fairies': 362, 'except': 349, 'knock': 584, 'teeth': 1104, 'cash': 166, 'hope': 517, 'name': 736, 'gold': 457, 'card': 160, 'blowjob': 107, 'drink': 314, 'moose': 718, 'knuckle': 587, 'first': 390, 'ain': 13, 'taking': 1093, 'babysitting': 58, 'alright': 24, 'sure': 1081, 'miss': 704, 'uh': 1173, 'mhm': 696, 'kid': 568, 'light': 619, 'stalking': 1047, 'age': 8, 'traveling': 1155, 'exotic': 355, 'baghdad': 63, 'mogadishu': 710, 'jacksonville': 545, 'meeting': 685, 'new': 750, 'exciting': 352, 'people': 810, 'classified': 199, 'wonderful': 1249, 'tgi': 1110, 'friday': 415, 'kelly': 564, 'could': 240, 'bring': 130, 'bob': 108, 'please': 829, 'buck': 136, 'shits': 974, 'disturb': 304, 'cheers': 182, 'health': 490, 'picked': 818, 'boothe': 112, 'pick': 817, 'no': 757, 'bet': 90, 'die': 292, 'wow': 1267, 'joke': 555, 'living': 634, 'dying': 323, 'city': 198, 'detroit': 285, 'whatever': 1224, 'soldiers': 1019, 'fortune': 407, 'drinks': 315, 'what': 1223, 'place': 826, 'apologize': 40, 'before': 81, 'breath': 127, 'nose': 762, 'woah': 1247, 'hakuna': 472, 'tatas': 1098, 'sorry': 1026, 'cast': 168, 'spell': 1035, 'merchandise': 690, 'warm': 1198, 'fuzzys': 431, 'rough': 912, 'childhood': 186, 'daddy': 262, 'left': 606, 'conceived': 228, 'put': 866, 'uncle': 1176, 'watched': 1204, 'birthday': 93, 'party': 802, 'keyhole': 566, 'locked': 636, 'closet': 203, 'also': 25, 'happens': 480, 'dishwasher': 302, 'didn': 290, 'even': 342, 'sleep': 1006, 'pretty': 847, 'ball': 65, 'gags': 434, 'brownie': 135, 'mix': 708, 'clown': 204, 'porn': 837, 'hopefully': 518, 'later': 596, 'yogurt': 1281, 'lite': 629, 'rewards': 889, 'holes': 513, 'want': 1196, 'tough': 1147, 'call': 149, 'real': 874, 'short': 985, 'dimensional': 296, 'sex': 962, 'object': 768, 'peddled': 807, 'hollywood': 515, 'prepare': 844, 'lose': 643, 'tragically': 1151, 'okay': 774, 'ruhroh': 915, 'limited': 622, 'edition': 328, 'voltron': 1186, 'defender': 280, 'universe': 1180, 'ring': 895, 'por': 835, 'favor': 373, 'eye': 357, 'sucker': 1072, 'lady': 590, 'many': 666, 'fyi': 432, 'five': 391, 'minilion': 702, 'bots': 117, 'come': 217, 'together': 1137, 'form': 406, 'superlion': 1080, 'bot': 115, 'remaining': 882, 'thirty': 1124, 'seconds': 944, 'happy': 482, 'chinese': 190, 'lent': 610, 'halloween': 475, 'leg': 607, 'thanksgiving': 1113, 'visit': 1185, 'holidays': 514, 'sweater': 1085, 'terrible': 1108, 'looks': 642, 'listen': 628, 'crazy': 247, 'matches': 673, 'jigsaw': 551, 'pieces': 819, 'um': 1175, 'weird': 1215, 'curvy': 259, 'edges': 327, 'marry': 669, 'nowhere': 764, 'spent': 1036, 'month': 717, 'salary': 924, 'so': 1016, 'posed': 839, 'yes': 1278, 'feel': 377, 'held': 495, 'star': 1050, 'wars': 1201, 'jokes': 556, 'jesus': 550, 'christ': 192, 'computer': 226, 'perfect': 813, 'pee': 808, 'break': 125, 'shake': 964, 'here': 500, 'life': 618, 'endless': 337, 'series': 957, 'trainwrecks': 1152, 'brief': 129, 'commercial': 224, 'breaks': 126, 'happiness': 481, 'ultimate': 1174, 'meant': 681, 'return': 887, 'regularly': 881, 'scheduled': 939, 'program': 854, 'clowning': 205, 'sense': 955, 'clowns': 206, 'vanessa': 1184, 'already': 23, 'plan': 828, 'memorizing': 688, 'details': 284, 'seeing': 947, 'last': 594, 'twohundred': 1170, 'pound': 842, 'sack': 919, 'assholes': 50, 'named': 737, 'hide': 505, 'hush': 527, 'falls': 364, 'crowd': 253, 'rookie': 908, 'sensation': 954, 'regina': 880, 'saskatchewan': 930, 'shot': 986, 'thats': 1115, 'rhymes': 892, 'fun': 428, 'ladies': 589, 'gentlemen': 441, 'youre': 1285, 'witnessing': 1245, 'dickkicking': 288, 'revenge': 888, 'giving': 454, 'business': 144, 'incoming': 537, 'unsportsmanlike': 1181, 'conduct': 230, 'level': 615, 'rested': 886, 'youve': 1286, 'pitching': 823, 'catching': 170, 'ringing': 896, 'bells': 85, 'bit': 95, 'radioactive': 868, 'sharpei': 967, 'whose': 1235, 'fault': 372, 'undo': 1179, 'butterface': 146, 'limp': 623, 'bizkit': 97, 'music': 732, 'late': 595, 'dad': 261, 'agree': 10, 'went': 1218, 'sideways': 991, 'colossal': 215, 'maybe': 677, 'prized': 849, 'possession': 840, 'wham': 1222, 'big': 91, 'album': 16, 'george': 442, 'andy': 28, 'exclamation': 353, 'spring': 1044, 'cleaning': 200, 'death': 276, 'god': 455, 'nickel': 753, 'every': 344, 'spanked': 1032, 'bernadette': 87, 'peters': 815, 'cancers': 157, 'liver': 633, 'lungs': 654, 'prostate': 858, 'brain': 123, 'things': 1121, 'live': 632, 'without': 1244, 'cancer': 156, 'shitshow': 975, 'yakoff': 1271, 'smirnoff': 1012, 'opening': 783, 'spin': 1037, 'doctors': 305, 'iowa': 540, 'state': 1054, 'circumstances': 196, 'ghost': 447, 'swear': 1084, 'gon': 458, 'next': 751, 'boombox': 111, 'careless': 162, 'whisper': 1230, 'outside': 791, 'window': 1240, 'wease': 1212, 'shots': 987, 'patron': 804, 'sound': 1027, 'check': 181, 'shes': 969, 'sending': 953, 'colorful': 214, 'clinic': 202, 'brochures': 131, 'theyre': 1118, 'fda': 375, 'approved': 42, 'chechnya': 180, 'isnt': 542, 'weve': 1220, 'china': 189, 'central': 173, 'mexico': 695, 'say': 937, 'spanish': 1031, 'besides': 88, 'luring': 655, 'children': 187, 'panel': 797, 'van': 1183, 'alert': 17, 'rate': 871, 'folks': 399, 'haircut': 471, 'wash': 1202, 'taste': 1096, 'impressive': 534, 'change': 177, 'infomercial': 538, 'slapchop': 1005, 'shakeweighty': 965, 'look': 639, 'agent': 9, 'smith': 1013, 'tried': 1158, 'mark': 668, 'ever': 343, 'hit': 508, 'ill': 530, 'within': 1243, 'yards': 1273, 'school': 940, 'wan': 1194, 'liam': 616, 'neeson': 743, 'nightmare': 755, 'dreamt': 313, 'kidnapped': 571, 'daughter': 267, 'wasnt': 1203, 'movies': 726, 'wonder': 1248, 'hes': 503, 'parent': 800, 'part': 801, 'knew': 582, 'save': 934, 'superheroes': 1078, 'lets': 613, 'procon': 853, 'pro': 850, 'pull': 862, 'gaggle': 433, 'dry': 319, 'cleaningdiscounts': 201, 'lucrative': 652, 'film': 385, 'deals': 275, 'origin': 788, 'larger': 593, 'ensemble': 339, 'team': 1100, 'con': 227, 'lameass': 591, 'teachers': 1099, 'pets': 816, 'talking': 1094, 'colossus': 216, 'dont': 310, 'goodytwoshoes': 461, 'bullshit': 141, 'negasonic': 744, 'teenage': 1103, 'coolest': 237, 'sidekick': 990, 'guess': 467, 'xmen': 1270, 'behind': 83, 'detail': 283, 'pretending': 846, 'warhead': 1197, 'trade': 1150, 'names': 738, 'rather': 872, 'anywhere': 37, 'long': 638, 'sullen': 1074, 'silences': 993, 'followed': 400, 'mean': 679, 'comments': 223, 'whats': 1225, 'huh': 525, 'silence': 992, 'comment': 222, 'ahhah': 12, 'chrome': 194, 'cockgobbler': 210, 'trust': 1160, 'wheezing': 1226, 'dick': 287, 'tips': 1135, 'coming': 220, 'pure': 865, 'evil': 347, 'nobodys': 758, 'heads': 488, 'decide': 278, 'become': 79, 'crimefighting': 250, 'shitswizzler': 977, 'rooms': 910, 'bunch': 142, 'whiners': 1229, 'neverland': 749, 'mansion': 665, 'creepy': 248, 'old': 775, 'bald': 64, 'heavens': 494, 'gatelooking': 437, 'send': 952, 'shiny': 971, 'request': 885, 'either': 331, 'slap': 1004, 'bitch': 96, 'zip': 1288, 'sinead': 996, 'watching': 1205, 'canada': 155, 'cock': 209, 'poor': 834, 'wife': 1237, 'dinosaurs': 298, 'feared': 376, 'trex': 1157, 'promise': 856, 'boy': 120, 'hear': 491, 'onelegged': 778, 'asskicking': 51, 'contest': 235, 'switch': 1087, 'mcavoy': 678, 'stewart': 1057, 'timelines': 1133, 'confusing': 232, 'alive': 19, 'camera': 152, 'hours': 521, 'spoiler': 1039, 'theres': 1117, 'baby': 56, 'rock': 903, 'meet': 684, 'bottom': 118, 'ends': 338, 'breathtakingly': 128, 'generally': 439, 'trace': 1149, 'decision': 279, 'sent': 956, 'road': 899, 'shittsburgh': 980, 'mine': 700, 'youll': 1284, 'green': 464, 'animated': 32, 'seems': 948, 'sanitary': 928, 'warmer': 1199, 'hands': 477, 'table': 1089, 'safe': 922, 'word': 1254, 'fellas': 381, 'pork': 836, 'beans': 74, 'arent': 43, 'strong': 1067, 'calling': 150, 'wang': 1195, 'oral': 785, 'fixation': 393, 'stallone': 1048, 'fan': 366, 'turn': 1163, 'service': 960, 'excited': 351, 'camp': 153, 'thank': 1111, 'middle': 697, 'romaine': 906, 'lettuce': 614, 'bothering': 116, 'ajax': 15, 'actual': 3, 'sounds': 1028, 'suspiciously': 1082, 'kevin': 565, 'ruth': 917, 'scott': 941, 'mitch': 707, 'dexter': 286, 'basil': 71, 'fawlty': 374, 'alone': 21, 'less': 611, 'angry': 31, 'rosie': 911, 'odonnell': 770, 'bucket': 137, 'spliff': 1038, 'olympic': 777, 'torch': 1142, 'forget': 404, 'naked': 735, 'tandem': 1095, 'base': 70, 'jumping': 557, 'wnba': 1246, 'sacramento': 920, 'monarchs': 713, 'meredith': 691, 'baxter': 73, 'birney': 92, 'dutch': 322, 'oven': 793, 'cunningham': 257, 'legal': 608, 'dish': 301, 'soap': 1017, 'oops': 781, 'snabbed': 1015, 'drycleaning': 320, 'tag': 1090, 'lab': 588, 'coat': 207, 'discount': 300, 'heard': 492, 'wouldnt': 1265, 'heres': 501, 'problem': 852, 'roundtheclock': 913, 'torture': 1143, 'cant': 158, 'step': 1056, 'thought': 1125, 'dicks': 289, 'actually': 4, 'weekend': 1213, 'horror': 519, 'sadistic': 921, 'lips': 626, 'sealed': 942, 'didnt': 291, 'cure': 258, 'everything': 346, 'mattered': 674, 'making': 661, 'ugly': 1172, 'monster': 716, 'inside': 539, 'circus': 197, 'fugly': 426, 'mug': 730, 'shitstick': 976, 'mutant': 734, 'factory': 360, 'gone': 459, 'poof': 832, 'damn': 264, 'straight': 1065, 'work': 1257, 'crew': 249, 'somebody': 1021, 'gives': 453, 'force': 403, 'bullet': 139, 'skull': 1003, 'hole': 512, 'wear': 1210, 'mask': 670, 'testicle': 1109, 'thatll': 1114, 'captain': 159, 'nuts': 767, 'ask': 47, 'twice': 1167, 'wheres': 1228, 'killed': 574, 'zamboni': 1287, 'jared': 546, 'footlong': 402, 'fully': 427, 'loaded': 635, 'confirmed': 231, 'kills': 575, 'ding': 297, 'end': 335, 'boss': 114, 'might': 698, 'piggy': 820, 'whoops': 1234, 'werent': 1219, 'caught': 171, 'bleeding': 102, 'garbage': 436, 'seltzer': 951, 'water': 1206, 'lemon': 609, 'blood': 106, 'whoo': 1233, 'kinds': 579, 'anger': 29, 'managed': 664, 'yearlong': 1276, 'dismembered': 303, 'comes': 218, 'licking': 617, 'wounds': 1266, 'home': 516, 'met': 693, 'blind': 103, 'laundry': 598, 'mat': 672, 'fourth': 411, 'wall': 1191, 'sixteen': 1001, 'walls': 1193, 'robin': 900, 'batman': 72, 'black': 99, 'loves': 649, 'morning': 719, 'sleepy': 1007, 'head': 486, 'smells': 1011, 'comfy': 219, 'rubber': 914, 'masturbatin': 671, 'shoes': 982, 'sit': 998, 'stick': 1058, 'bactine': 60, 'hows': 523, 'cunen': 256, 'along': 22, 'ikea': 529, 'doesnt': 306, 'assemble': 49, 'anythings': 35, 'improvement': 536, 'holdall': 511, 'taken': 1092, 'emness': 334, 'tristes': 1159, 'saw': 936, 'kidding': 569, 'decades': 277, 'grossed': 465, 'quote': 867, 'likes': 621, 'imperfections': 532, 'must': 733, 'build': 138, 'pay': 806, 'rent': 884, 'recap': 877, 'cockthistle': 211, 'freak': 414, 'slipped': 1010, 'arms': 45, 'arm': 44, 'chance': 174, 'sexy': 963, 'prevent': 848, 'happening': 479, 'sand': 927, 'paper': 799, 'dildo': 294, 'hashtag': 484, 'drive': 316, 'stuck': 1068, 'raided': 869, 'stash': 1053, 'wisdom': 1242, 'percocet': 812, 'orbiting': 786, 'saturn': 932, 'appreciate': 41, 'gesture': 443, 'size': 1002, 'kfc': 567, 'spork': 1041, 'telling': 1106, 'mrs': 727, 'magoo': 658, 'youd': 1283, 'understand': 1178, 'david': 268, 'beckham': 78, 'speak': 1034, 'mouthsexed': 723, 'helium': 496, 'ryan': 918, 'reynolds': 890, 'far': 367, 'superior': 1079, 'acting': 2, 'method': 694, 'till': 1131, 'plows': 830, 'puberty': 861, 'meantime': 682, 'room': 909, 'feels': 378, 'huge': 524, 'hand': 476, 'believe': 84, 'half': 473, 'afraid': 7, 'fast': 370, 'numbnuts': 766, 'constantly': 234, 'fox': 412, 'especially': 341, 'angle': 30, 'weak': 1209, 'motherfucker': 722, 'whered': 1227, 'chocolate': 191, 'jimminy': 552, 'rip': 897, 'guns': 468, 'careful': 161, 'ronnie': 907, 'milsap': 699, 'downrange': 312, 'told': 1138, 'oordvash': 782, 'bjorsha': 98, 'outta': 792, 'town': 1148, 'cough': 239, 'kilos': 576, 'cocaine': 208, 'buried': 143, 'somewhere': 1024, 'apartment': 39, 'blindness': 104, 'luck': 650, 'ripley': 898, 'alien': 18, 'fake': 363, 'laugh': 597, 'hiding': 506, 'pain': 795, 'silver': 994, 'eating': 326, 'sundown': 1075, 'saving': 935, 'offer': 771, 'refuse': 879, 'house': 522, 'funny': 429, 'almost': 20, 'studio': 1069, 'couldnt': 241, 'afford': 6, 'another': 33, 'xman': 1269, 'opinion': 784, 'cocoon': 212, 'pornography': 838, 'twinkly': 1168, 'deadly': 273, 'chromepenised': 195, 'agreed': 11, 'solid': 1020, 'exchange': 350, 'consider': 233, 'joining': 554, 'band': 67, 'winning': 1241, 'gita': 450, 'darn': 266, 'cute': 260, 'absolutely': 0, 'lost': 644, 'translation': 1153, 'win': 1239, 'gitas': 451, 'heart': 493, 'proud': 859, 'drop': 318, 'bantu': 69, 'gentle': 440, 'fashioned': 369, 'boyish': 122, 'charm': 179, 'kidnap': 570, 'difference': 293, 'chimi': 188, 'changas': 176, 'often': 772, 'dude': 321, 'stomps': 1060, 'sanity': 929, 'grabs': 463, 'future': 430, 'babymomma': 57, 'personally': 814, 'sees': 950, 'shittiest': 978, 'moments': 712, 'beginning': 82, 'lot': 645, 'swords': 1088, 'cue': 255, 'imma': 531, 'landing': 592, 'woo': 1252, 'knees': 581, 'impractical': 533, 'lovely': 647, 'finish': 388, 'tweet': 1165, 'second': 943, 'tiger': 1128, 'pity': 824, 'pressures': 845, 'prom': 855, 'suck': 1071, 'child': 185, 'spackled': 1029, 'muffin': 729, 'fart': 368, 'yall': 1272, 'lay': 600, 'firearms': 389, 'preferential': 843, 'borderline': 113, 'possibly': 841, 'loverlike': 648, 'treatment': 1156, 'commando': 221, 'havent': 485, 'since': 995, 'fridays': 416, 'hell': 497, 'gale': 435, 'still': 1059, 'fixing': 394, 'tuna': 1162, 'casserole': 167, 'waistline': 1188, 'worry': 1261, 'worn': 1260, 'color': 213, 'shitbox': 973, 'theyve': 1119, 'blocked': 105, 'nerve': 746, 'dance': 265, 'try': 1161, 'saturday': 931, 'night': 754, 'top': 1141, 'yoohoo': 1282, 'awe': 55, 'words': 1255, 'headed': 487, 'admits': 5, 'cares': 163, 'droning': 317, 'pepperoni': 811, 'flatbread': 396, 'least': 602, 'fuckface': 423, 'wont': 1251, 'heal': 489, 'wearing': 1211, 'tights': 1130, 'means': 680, 'sparing': 1033, 'psychopaths': 860, 'everyone': 345, 'monitors': 715, 'hall': 474, 'lookout': 641, 'stand': 1049, 'front': 419, 'deserve': 282, 'nethers': 747, 'leaving': 605, 'cowboying': 245, 'sooner': 1025, 'couple': 244, 'years': 1277, 'crack': 246, 'family': 365, 'spoon': 1040, 'warmth': 1200, 'fights': 383, 'noelle': 759, 'fattest': 371, 'nothing': 763, 'floorspace': 397, 'dental': 281, 'floss': 398, 'condoms': 229, 'found': 408, 'case': 165, 'fell': 379, 'bandaid': 68, 'audi': 52, 'underneath': 1177, 'penis': 809, 'useful': 1182, 'brother': 132, 'beast': 75, 'stop': 1061, 'shitting': 979, 'lawn': 599, 'chicken': 184, 'noodle': 760, 'compares': 225, 'oconnor': 769, 'felt': 382, 'mini': 701, 'lion': 625, 'robots': 902, 'robot': 901, 'moment': 711, 'ive': 543, 'promised': 857, 'epic': 340, 'wide': 1236, 'pulling': 863, 'ending': 336, 'friendly': 418, 'neighborhood': 745, 'saying': 938, 'expecting': 356, 'teaser': 1101, 'sam': 926, 'jackson': 544, 'patch': 803, 'saucy': 933, 'number': 765, 'secret': 945, 'cable': 148, 'amazing': 26, 'character': 178, 'mechanic': 683, 'travel': 1154, 'anybody': 34, 'flat': 395, 'mel': 687, 'gibson': 448, 'dolph': 307, 'lundgren': 653, 'keira': 563, 'knightley': 583, 'range': 870, 'shh': 970, 'lying': 656, 'around': 46, 'total': 1144, 'move': 724, 'chickachicka': 183}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lm7hXNV5Uwxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bUbC56-NckA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sentiment"
      ]
    },
    {
      "metadata": {
        "id": "SRGJlMBgdXxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "96062911-4035-4e4c-b83d-27fa25fd84f9"
      },
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6uTgTttNdfHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "56e6efa1-fa6d-4c02-e541-fbbd3dd17239"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "h2t0OjTOdbus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbX80mT6dvNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66eb854a-9668-4ddc-f6ce-362e1392b017"
      },
      "cell_type": "code",
      "source": [
        "dp_all[\"clean2\"][5]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pool dead'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "THW5eUoKdpuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = sid.polarity_scores(dp_all[\"clean2\"][5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qivHfWOd1QE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2ce1386-42ce-4935-b3b5-181940e45966"
      },
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.6486, 'neg': 0.811, 'neu': 0.189, 'pos': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "DJvFGEBZzO9w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s  = pd.DataFrame.from_dict([scores])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkhZNgbxz1Nl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "09f3b318-4d40-43ea-c967-db78bbf44c6a"
      },
      "cell_type": "code",
      "source": [
        "s"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compound</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.6486</td>\n",
              "      <td>0.811</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   compound    neg    neu  pos\n",
              "0   -0.6486  0.811  0.189  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "k_6V-5xVeJnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "340a39cc-102a-4f0e-b082-050ebd33082a"
      },
      "cell_type": "code",
      "source": [
        "for key in sorted(scores):\n",
        "        print('{0}: {1}, '.format(key, scores[key]), end='')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compound: -0.6486, neg: 0.811, neu: 0.189, pos: 0.0, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5jXW1Abb0SNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "021cc4b7-b11f-4d1e-e02b-b1dc1206c05e"
      },
      "cell_type": "code",
      "source": [
        "scores.values()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([0.811, 0.189, 0.0, -0.6486])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "ZffJzsQ0bjrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcaacb19-738a-4e43-9d2a-50b4229e3cfc"
      },
      "cell_type": "code",
      "source": [
        "scores.get(\"compound\") "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6486"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "j1ePHQObfLYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b145f45b-0a49-4867-8e10-d85088ecdd97"
      },
      "cell_type": "code",
      "source": [
        "dp_all[\"sentiment\"] = dp_all[\"clean2\"].apply(lambda x : sid.polarity_scores(x))\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fbur5GL3o_61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "734b5573-2d64-4592-a78c-0abf025059fc"
      },
      "cell_type": "code",
      "source": [
        "dp_all[\"compound\"] = dp_all[\"clean2\"].apply(lambda x : sid.polarity_scores(x).get(\"compound\") )\n",
        "dp_all[\"neg\"] = dp_all[\"clean2\"].apply(lambda x : sid.polarity_scores(x).get(\"neg\") )\n",
        "dp_all[\"neu\"] = dp_all[\"clean2\"].apply(lambda x : sid.polarity_scores(x).get(\"neu\") )\n",
        "dp_all[\"pos\"] = dp_all[\"clean2\"].apply(lambda x : sid.polarity_scores(x).get(\"pos\") )"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gyugOwSgmfFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "6db749a8-bedc-4a9b-d3bd-0ab29f2f674a"
      },
      "cell_type": "code",
      "source": [
        "dp_all.sample(10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WHO</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>tokenized_sentences</th>\n",
              "      <th>stemmed2</th>\n",
              "      <th>stemmed3</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>clean</th>\n",
              "      <th>clean2</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>compound</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>bad deadpool</td>\n",
              "      <td>[bad, deadpool]</td>\n",
              "      <td>[bad, deadpool]</td>\n",
              "      <td>[bad, deadpool]</td>\n",
              "      <td>[bad, deadpool]</td>\n",
              "      <td>bad deadpool</td>\n",
              "      <td>bad deadpool</td>\n",
              "      <td>{'neg': 0.778, 'neu': 0.222, 'pos': 0.0, 'comp...</td>\n",
              "      <td>-0.5423</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>WADE</td>\n",
              "      <td>yeah</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>[yeah]</td>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>WADE</td>\n",
              "      <td>id say sound like infomercial good one like sl...</td>\n",
              "      <td>[id, say, sound, like, infomercial, good, one,...</td>\n",
              "      <td>[id, say, sound, lik, infomerc, good, on, lik,...</td>\n",
              "      <td>[id, say, sound, like, infomerci, good, one, l...</td>\n",
              "      <td>[id, say, sound, like, infomercial, good, one,...</td>\n",
              "      <td>id say sound like infomercial good like slapch...</td>\n",
              "      <td>say sound like infomercial good like slapchop ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.388, 'pos': 0.612, 'comp...</td>\n",
              "      <td>0.7845</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>never let go don’t make mistakes got</td>\n",
              "      <td>[never, let, go, don, ’, t, make, mistakes, got]</td>\n",
              "      <td>[nev, let, go, don, ’, t, mak, mistak, got]</td>\n",
              "      <td>[never, let, go, don, ’, t, make, mistak, got]</td>\n",
              "      <td>[never, let, go, don, ’, t, make, mistake, got]</td>\n",
              "      <td>never let go don ’ t make mistakes got</td>\n",
              "      <td>never let don make mistakes got</td>\n",
              "      <td>{'neg': 0.333, 'neu': 0.667, 'pos': 0.0, 'comp...</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>hey oh</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>[hey, oh]</td>\n",
              "      <td>hey oh</td>\n",
              "      <td>hey</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>WADE</td>\n",
              "      <td>megan</td>\n",
              "      <td>[megan]</td>\n",
              "      <td>[meg]</td>\n",
              "      <td>[megan]</td>\n",
              "      <td>[megan]</td>\n",
              "      <td>megan</td>\n",
              "      <td>megan</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>maximum effort</td>\n",
              "      <td>[maximum, effort]</td>\n",
              "      <td>[maxim, effort]</td>\n",
              "      <td>[maximum, effort]</td>\n",
              "      <td>[maximum, effort]</td>\n",
              "      <td>maximum effort</td>\n",
              "      <td>maximum effort</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>WADE</td>\n",
              "      <td>like wear mask</td>\n",
              "      <td>[like, wear, mask]</td>\n",
              "      <td>[lik, wear, mask]</td>\n",
              "      <td>[like, wear, mask]</td>\n",
              "      <td>[like, wear, mask]</td>\n",
              "      <td>like wear mask</td>\n",
              "      <td>like wear mask</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.444, 'pos': 0.556, 'comp...</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>shit</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>[shit]</td>\n",
              "      <td>shit</td>\n",
              "      <td>shit</td>\n",
              "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>-0.5574</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>DEADPOOL</td>\n",
              "      <td>shit biscuit francis</td>\n",
              "      <td>[shit, biscuit, francis]</td>\n",
              "      <td>[shit, biscuit, frant]</td>\n",
              "      <td>[shit, biscuit, franci]</td>\n",
              "      <td>[shit, biscuit, francis]</td>\n",
              "      <td>shit biscuit francis</td>\n",
              "      <td>shit biscuit francis</td>\n",
              "      <td>{'neg': 0.643, 'neu': 0.357, 'pos': 0.0, 'comp...</td>\n",
              "      <td>-0.5574</td>\n",
              "      <td>0.643</td>\n",
              "      <td>0.357</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          WHO                                               TEXT  \\\n",
              "69   DEADPOOL                                       bad deadpool   \n",
              "433      WADE                                               yeah   \n",
              "305      WADE  id say sound like infomercial good one like sl...   \n",
              "15   DEADPOOL               never let go don’t make mistakes got   \n",
              "63   DEADPOOL                                             hey oh   \n",
              "114      WADE                                              megan   \n",
              "49   DEADPOOL                                     maximum effort   \n",
              "445      WADE                                     like wear mask   \n",
              "67   DEADPOOL                                               shit   \n",
              "78   DEADPOOL                               shit biscuit francis   \n",
              "\n",
              "                                   tokenized_sentences  \\\n",
              "69                                     [bad, deadpool]   \n",
              "433                                             [yeah]   \n",
              "305  [id, say, sound, like, infomercial, good, one,...   \n",
              "15    [never, let, go, don, ’, t, make, mistakes, got]   \n",
              "63                                           [hey, oh]   \n",
              "114                                            [megan]   \n",
              "49                                   [maximum, effort]   \n",
              "445                                 [like, wear, mask]   \n",
              "67                                              [shit]   \n",
              "78                            [shit, biscuit, francis]   \n",
              "\n",
              "                                              stemmed2  \\\n",
              "69                                     [bad, deadpool]   \n",
              "433                                             [yeah]   \n",
              "305  [id, say, sound, lik, infomerc, good, on, lik,...   \n",
              "15         [nev, let, go, don, ’, t, mak, mistak, got]   \n",
              "63                                           [hey, oh]   \n",
              "114                                              [meg]   \n",
              "49                                     [maxim, effort]   \n",
              "445                                  [lik, wear, mask]   \n",
              "67                                              [shit]   \n",
              "78                              [shit, biscuit, frant]   \n",
              "\n",
              "                                              stemmed3  \\\n",
              "69                                     [bad, deadpool]   \n",
              "433                                             [yeah]   \n",
              "305  [id, say, sound, like, infomerci, good, one, l...   \n",
              "15      [never, let, go, don, ’, t, make, mistak, got]   \n",
              "63                                           [hey, oh]   \n",
              "114                                            [megan]   \n",
              "49                                   [maximum, effort]   \n",
              "445                                 [like, wear, mask]   \n",
              "67                                              [shit]   \n",
              "78                             [shit, biscuit, franci]   \n",
              "\n",
              "                                            lemmatized  \\\n",
              "69                                     [bad, deadpool]   \n",
              "433                                             [yeah]   \n",
              "305  [id, say, sound, like, infomercial, good, one,...   \n",
              "15     [never, let, go, don, ’, t, make, mistake, got]   \n",
              "63                                           [hey, oh]   \n",
              "114                                            [megan]   \n",
              "49                                   [maximum, effort]   \n",
              "445                                 [like, wear, mask]   \n",
              "67                                              [shit]   \n",
              "78                            [shit, biscuit, francis]   \n",
              "\n",
              "                                                 clean  \\\n",
              "69                                        bad deadpool   \n",
              "433                                               yeah   \n",
              "305  id say sound like infomercial good like slapch...   \n",
              "15              never let go don ’ t make mistakes got   \n",
              "63                                              hey oh   \n",
              "114                                              megan   \n",
              "49                                      maximum effort   \n",
              "445                                     like wear mask   \n",
              "67                                                shit   \n",
              "78                                shit biscuit francis   \n",
              "\n",
              "                                                clean2  \\\n",
              "69                                        bad deadpool   \n",
              "433                                               yeah   \n",
              "305  say sound like infomercial good like slapchop ...   \n",
              "15                     never let don make mistakes got   \n",
              "63                                                 hey   \n",
              "114                                              megan   \n",
              "49                                      maximum effort   \n",
              "445                                     like wear mask   \n",
              "67                                                shit   \n",
              "78                                shit biscuit francis   \n",
              "\n",
              "                                             sentiment  compound    neg  \\\n",
              "69   {'neg': 0.778, 'neu': 0.222, 'pos': 0.0, 'comp...   -0.5423  0.778   \n",
              "433  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...    0.2960  0.000   \n",
              "305  {'neg': 0.0, 'neu': 0.388, 'pos': 0.612, 'comp...    0.7845  0.000   \n",
              "15   {'neg': 0.333, 'neu': 0.667, 'pos': 0.0, 'comp...   -0.3612  0.333   \n",
              "63   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000   \n",
              "114  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000   \n",
              "49   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000   \n",
              "445  {'neg': 0.0, 'neu': 0.444, 'pos': 0.556, 'comp...    0.3612  0.000   \n",
              "67   {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...   -0.5574  1.000   \n",
              "78   {'neg': 0.643, 'neu': 0.357, 'pos': 0.0, 'comp...   -0.5574  0.643   \n",
              "\n",
              "       neu    pos  \n",
              "69   0.222  0.000  \n",
              "433  0.000  1.000  \n",
              "305  0.388  0.612  \n",
              "15   0.667  0.000  \n",
              "63   1.000  0.000  \n",
              "114  1.000  0.000  \n",
              "49   1.000  0.000  \n",
              "445  0.444  0.556  \n",
              "67   0.000  0.000  \n",
              "78   0.357  0.000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "xIXZjLh3dBq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "33fc3204-e2ff-4e58-8fc3-b0802b727592"
      },
      "cell_type": "code",
      "source": [
        "dp_all.groupby('WHO')['pos'].mean() "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WHO\n",
              "DEADPOOL    0.170624\n",
              "WADE        0.258589\n",
              "Name: pos, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "0xM6OLludJkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f53efbd7-5350-4d21-b086-f53ec92261c1"
      },
      "cell_type": "code",
      "source": [
        "dp_all.groupby('WHO')['neg'].mean()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WHO\n",
              "DEADPOOL    0.166335\n",
              "WADE        0.116146\n",
              "Name: neg, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "2kNXjHGfdK5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "8392e5cf-2cb4-42e2-b0b5-a435c30a82a7"
      },
      "cell_type": "code",
      "source": [
        "dp_all.groupby('WHO')['neu'].mean()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WHO\n",
              "DEADPOOL    0.621757\n",
              "WADE        0.598781\n",
              "Name: neu, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "hxbL193cdRdV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wade is more positive?"
      ]
    }
  ]
}
